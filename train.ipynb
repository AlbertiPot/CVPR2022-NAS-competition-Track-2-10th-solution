{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Codes\n",
    "## Implementation\n",
    "MLP + ranking based loss\n",
    "## Two ways to reproduce the training procedure\n",
    "1. directly running the bash scripts\n",
    "2. running the notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 running the bash scripts\n",
    "!bash train.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 running and debugging in the notebook\n",
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import copy\n",
    "import json\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from dataset import ArchPerfDataset\n",
    "from network import AutoEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed, ranking based loss, norm the final relative scores to rankings\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    cudnn.benchmark = True\n",
    "    cudnn.enabled = True\n",
    "    cudnn.deterministic = True \n",
    "\n",
    "def pair_loss(outputs, labels): # output.shape = torch.Size([1023]) labels = torch.Size([1023])\n",
    "    \n",
    "    output = outputs.unsqueeze(1)\n",
    "    output1 = output.repeat(1,outputs.shape[0])\n",
    "    label = labels.unsqueeze(1)\n",
    "    label1 = label.repeat(1,labels.shape[0])\n",
    "    tmp = (output1-output1.t())*torch.sign(label1-label1.t())\n",
    "    tmp = torch.log(1+torch.exp(-tmp))\n",
    "    eye_tmp = tmp*torch.eye(len(tmp)).cuda()\n",
    "    new_tmp = tmp - eye_tmp\n",
    "    loss = torch.sum(new_tmp)/(outputs.shape[0]*(outputs.shape[0]-1))\n",
    "    return loss\n",
    "def norm_list(scores):\n",
    "    scores_ls_sort=scores.tolist()\n",
    "    scores_ls=scores.tolist()\n",
    "    scores_ls_sort.sort()\n",
    "    rank_number=[]\n",
    "    for item in scores_ls:\n",
    "        rank=scores_ls_sort.index(item)\n",
    "        rank_number.append(rank)\n",
    "    return rank_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch train,val and test\n",
    "def train_epoch(model, criterion, optimizer, train_loader, epoch, log_interval):\n",
    "    \n",
    "    running_loss = 0\n",
    "    running_ktau = 0\n",
    "    for step, (archs, targets) in enumerate(train_loader):\n",
    "        \n",
    "        archs, targets = archs.cuda(), targets.cuda()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(archs)\n",
    "        outputs = outputs.squeeze(1)\n",
    "\n",
    "        # outputs.shape=torch.Size([16]) targets.shape = torch.Size([16])\n",
    "        # loss = criterion(outputs, targets)\n",
    "        loss = pair_loss(outputs, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        ktau, p_value = stats.kendalltau(outputs.detach().cpu().numpy(), targets.detach().cpu().numpy())\n",
    "        running_ktau += ktau\n",
    "        running_loss += loss.item()*archs.size(0)\n",
    "\n",
    "    epoch_loss = running_loss/(len(train_loader)*archs.size(0))\n",
    "    epoch_ktau = running_ktau/(step+1)\n",
    "\n",
    "    if (epoch+1)%log_interval ==0 or epoch ==0:\n",
    "        print('[Train] Epoch {}: Loss: {:.4f} ktau: {:.4f}'.format(epoch+1, epoch_loss, epoch_ktau))\n",
    "\n",
    "    return epoch_loss, epoch_ktau\n",
    "\n",
    "@torch.no_grad()\n",
    "def val_epoch(model, val_loader, epoch, log_interval):\n",
    "\n",
    "    running_ktau = 0\n",
    "    for step, (archs, targets) in enumerate(val_loader):\n",
    "        \n",
    "        archs, targets = archs.cuda(), targets.cuda()\n",
    "\n",
    "        outputs = model(archs)\n",
    "        outputs = outputs.squeeze(1)\n",
    "\n",
    "        ktau, p_value = stats.kendalltau(outputs.detach().cpu().numpy(), targets.detach().cpu().numpy())\n",
    "        running_ktau += ktau\n",
    "\n",
    "    epoch_ktau = running_ktau/(step+1)\n",
    "    if (epoch+1)%log_interval ==0 or epoch ==0:\n",
    "        print('[Validate] Epoch {}: ktau: {:.4f}'.format(epoch+1, epoch_ktau))\n",
    "        \n",
    "    return epoch_ktau\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, test_loader):\n",
    "    \n",
    "    total_output = []\n",
    "    for step, archs in enumerate(test_loader):\n",
    "\n",
    "        archs = archs.cuda()\n",
    "\n",
    "        outputs = model(archs)\n",
    "        outputs = list(outputs.squeeze(1).detach().cpu().numpy())\n",
    "        total_output = total_output + outputs\n",
    "\n",
    "    return total_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(target_type, args):\n",
    "    torch.cuda.set_device(args.gpu)\n",
    "    set_seed(args.seed)\n",
    "\n",
    "    g_cpu = torch.Generator()\n",
    "    g_cpu.manual_seed(args.seed)\n",
    "\n",
    "    print('before dataloader init',torch.randn(2,3))\n",
    "\n",
    "    train_data = ArchPerfDataset(root=args.data_path, target_type=target_type, train=True, encode_dimension=args.encode_dimension)\n",
    "    test_data = ArchPerfDataset(root=args.data_path, target_type=target_type, train=False, encode_dimension=args.encode_dimension)\n",
    "\n",
    "    indices = list(range(len(train_data)))\n",
    "    split = int(np.floor(args.train_ratio*len(train_data)))\n",
    "\n",
    "    train_loader = DataLoader(train_data, \n",
    "                            batch_size=args.batch_size,\n",
    "                            sampler=SubsetRandomSampler(indices[:split],generator=g_cpu),\n",
    "                            pin_memory=True,\n",
    "                            num_workers=args.num_workers,\n",
    "                            drop_last=True\n",
    "                            )\n",
    "    \n",
    "    val_loader = DataLoader(train_data, \n",
    "                            batch_size=args.batch_size,\n",
    "                            sampler=SubsetRandomSampler(indices[split:],generator=g_cpu),\n",
    "                            pin_memory=True,\n",
    "                            num_workers=args.num_workers,\n",
    "                            drop_last=True\n",
    "                            )\n",
    "\n",
    "    test_loader = DataLoader(test_data, \n",
    "                            batch_size=args.batch_size,\n",
    "                            pin_memory=True,\n",
    "                            shuffle=False,\n",
    "                            num_workers=args.num_workers,\n",
    "                            drop_last=False\n",
    "                            )\n",
    "    print('after dataloader init',torch.randn(2,3))\n",
    "\n",
    "    model = AutoEncoder(dropout=args.dropout_ratio).cuda()\n",
    "\n",
    "    criterion = nn.MSELoss().cuda()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "    scheduler = None\n",
    "    if args.cos:\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, float(args.num_epochs))\n",
    "\n",
    "    best_ktau = 0\n",
    "    best_epoch = 0\n",
    "    best_model_weights = copy.deepcopy(model.state_dict())\n",
    "    all_model_weights = {}\n",
    "    \n",
    "    for eps in range(args.num_epochs):\n",
    "        flag = '{}_train'.format(target_type)\n",
    "        model.train()\n",
    "        train_epoch_loss, train_epoch_ktau = train_epoch(model, criterion, optimizer, train_loader, eps, args.log_interval)\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        if (eps+1)%args.val_interval == 0 or eps==0:\n",
    "            flag = '{}_validate'.format(target_type)\n",
    "            model.eval()\n",
    "            epoch_ktau = val_epoch(model, val_loader, eps, args.log_interval)\n",
    "\n",
    "            if epoch_ktau > best_ktau:\n",
    "                best_ktau = epoch_ktau\n",
    "                best_epoch = eps+1\n",
    "                best_model_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "            # save model from every epoch\n",
    "            all_model_weights[epoch_ktau] = copy.deepcopy(model.state_dict())\n",
    "    torch.save(all_model_weights, './results/{}_epoch_inteval{}.pth'.format(target_type, args.val_interval))\n",
    "\n",
    "    print('Best train KTau: {:4f}@epoch {} on task {}'.format(best_ktau, best_epoch, target_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set default parameters\n",
    "parser = argparse.ArgumentParser(description='PyTorch Estimator Training')\n",
    "parser.add_argument('--data_path', type=str, default='./data/', help='dataset path')\n",
    "parser.add_argument('--train_ratio', type=float, default=0.9, help='ratio of train data')\n",
    "parser.add_argument('--lr', type=float, default=0.001)\n",
    "parser.add_argument('--weight_decay', type=float, default=3e-4)\n",
    "parser.add_argument('--num_epochs', type=int, default=400)\n",
    "parser.add_argument('--batch_size', type=int, default=16)\n",
    "parser.add_argument('--seed', type=int, default=1, help='random seed')\n",
    "parser.add_argument('--gpu', type=int, default=0, help='gpu device id')\n",
    "parser.add_argument('--log_interval', type=int, default=100)\n",
    "# parser.add_argument('--target_type', type=str, default='market1501_rank', help='8 target missions')\n",
    "parser.add_argument('--num_workers', type=int, default=4)\n",
    "parser.add_argument('--save_name', type=str, default='exp1')\n",
    "parser.add_argument('--encode_dimension', type=int, default=11)\n",
    "parser.add_argument('--dropout_ratio', type=float, default=0.5)\n",
    "parser.add_argument('--cos', action='store_true', default=False)\n",
    "parser.add_argument('--val_interval', type=int, default=1)\n",
    "\n",
    "args = parser.parse_args(args=['--data_path', './data/'])\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussions for hyper-parameters tunning:\n",
    "1. Low-ranking task like cplfw which has a ktau around the 0.3, indicates that the ViT model config has little to do with the final performance over such task. And this yields a hard optimization. In this situation, we select the small batch size (8 for cplfw) because we are afraid that a larger batch size would easily miss the sharp optimal point. Besides, the lr is fixed and not annealing to zero because we want the optimization process to have more chances to find the optimal points rather than falling into one sub-optimal point. This is certified during the hyper-parameters selection procedure.\n",
    "\n",
    "2. For high-ranking tasks, the optimization space is more smooth and easier to locate the optimal, so we adopt a larger batch size and enable the cos-annealing lr scheduling.\n",
    "\n",
    "3. Since the given training and validating samples are limited (500), the validating ktau is not trustful for selecting the final predictors to eval over the large search space (99500). So we save all the checkpoints on every n epoch (given in args.val_interval) and sort them according to the validation ktau. Then in the testing stage, we traverse the checkpoints with top ktau and obtain the final results on the test set. Finally, we upload and select the best one on board B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running 8 predictor training on 8 tasks\n",
    "\n",
    "task_list = [\"cplfw_rank\",\"vehicleid_rank\",\"dukemtmc_rank\",\"market1501_rank\",\"msmt17_rank\",\"veri_rank\",\"veriwild_rank\",\"sop_rank\"]\n",
    "\n",
    "with open('./data/CVPR_2022_NAS_Track2_test.json', 'r') as f:\n",
    "        test_data = json.load(f)\n",
    "\n",
    "for data_type in task_list:\n",
    "        if data_type == 'cplfw_rank':\n",
    "            # best: lr=1e-3, wd=6e-4 bsz=8, ratio=0.7, seed=4, dp=0.4, cos=False, val_interva=1\n",
    "            args.lr = 1e-3\n",
    "            args.weight_decay = 6e-4\n",
    "            args.batch_size = 8\n",
    "            args.train_ratio = 0.7\n",
    "            args.seed = 4\n",
    "            args.dropout_ratio = 0.4\n",
    "            args.cos=False\n",
    "            args.val_interval = 1\n",
    "        elif data_type == 'vehicleid_rank':\n",
    "            # current best: lr=1e-3, wd=6e-4 bsz=25, ratio=0.9, seed=4, dp=0.4, cos=True, val_inter=5\n",
    "            args.lr = 1e-3\n",
    "            args.weight_decay = 6e-4\n",
    "            args.batch_size = 25\n",
    "            args.train_ratio = 0.9\n",
    "            args.seed = 4\n",
    "            args.dropout_ratio = 0.4\n",
    "            args.cos=True\n",
    "            args.val_interval = 5\n",
    "        elif data_type == 'dukemtmc_rank':\n",
    "            # current best: lr=5e-4, wd=6e-4 bsz=25, ratio=0.9, seed=4, dp=0.4, cos=True, val_interval=1\n",
    "            args.lr = 5e-4\n",
    "            args.weight_decay = 6e-4\n",
    "            args.batch_size = 25\n",
    "            args.train_ratio = 0.9\n",
    "            args.seed=4\n",
    "            args.dropout_ratio=0.4\n",
    "            args.cos=True\n",
    "            args.val_interval = 1\n",
    "        elif data_type == 'market1501_rank':\n",
    "            args.lr = 1e-3\n",
    "            args.weight_decay = 6e-4\n",
    "            args.batch_size = 32\n",
    "            args.train_ratio = 0.9\n",
    "            args.seed=1\n",
    "            args.dropout_ratio=0.5\n",
    "            args.cos=False\n",
    "            args.val_interval = 1\n",
    "        elif data_type == 'msmt17_rank':\n",
    "            args.lr = 1e-3\n",
    "            args.weight_decay = 6e-4\n",
    "            args.batch_size = 32\n",
    "            args.train_ratio = 0.8\n",
    "            args.seed=1\n",
    "            args.dropout_ratio=0.4\n",
    "            args.cos=True\n",
    "            args.val_interval = 5\n",
    "        elif data_type == 'veri_rank':\n",
    "            args.lr = 1e-3\n",
    "            args.weight_decay = 6e-4\n",
    "            args.batch_size = 32\n",
    "            args.train_ratio = 0.8\n",
    "            args.seed=0\n",
    "            args.dropout_ratio=0.5\n",
    "            args.cos=True\n",
    "            args.val_interval = 5\n",
    "        elif data_type == 'veriwild_rank':\n",
    "            args.lr = 1e-3\n",
    "            args.weight_decay = 6e-4\n",
    "            args.batch_size = 32\n",
    "            args.train_ratio = 0.8\n",
    "            args.seed=3\n",
    "            args.dropout_ratio=0.5\n",
    "            args.cos=True\n",
    "            args.val_interval = 1\n",
    "        elif data_type == 'sop_rank':\n",
    "            args.lr = 1e-3\n",
    "            args.weight_decay = 6e-4\n",
    "            args.batch_size = 50\n",
    "            args.train_ratio = 0.8\n",
    "            args.seed=4\n",
    "            args.dropout_ratio=0.5\n",
    "            args.cos=True\n",
    "            args.val_interval = 1\n",
    "        print(args)\n",
    "\n",
    "        print('start to process task {}'.format(data_type))\n",
    "        \n",
    "        main(data_type, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the model checkpoints are stored in the dir, please run the test file to load the checkpoints and eval."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "303f209d9515745736caecbf6e28d85f87a490a49e3651540a01ca7db04ef59c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('rookie': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
